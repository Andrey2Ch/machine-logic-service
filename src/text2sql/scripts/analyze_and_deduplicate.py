#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ captured SQL –∑–∞–ø—Ä–æ—Å–æ–≤
"""
import sys
import os
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.text2sql.utils.sql_normalizer import (
    normalize_sql, 
    extract_table_names, 
    get_operation_type,
    is_good_question,
    calculate_quality_score,
    suggest_business_question
)
from src.database import get_db_connection
import psycopg2
from collections import defaultdict


def analyze_captured_queries():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç captured –∑–∞–ø—Ä–æ—Å—ã –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    print("üîç –ê–Ω–∞–ª–∏–∑ captured SQL –∑–∞–ø—Ä–æ—Å–æ–≤...")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    cur.execute("""
        SELECT 
            COUNT(*) as total,
            COUNT(question_ru) as with_questions,
            COUNT(*) - COUNT(question_ru) as without_questions
        FROM text2sql_captured
    """)
    total, with_questions, without_questions = cur.fetchone()
    
    print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total}")
    print(f"‚úÖ –° –≤–æ–ø—Ä–æ—Å–∞–º–∏: {with_questions}")
    print(f"‚ùå –ë–µ–∑ –≤–æ–ø—Ä–æ—Å–æ–≤: {without_questions}")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
    cur.execute("""
        SELECT sql, question_ru 
        FROM text2sql_captured 
        WHERE question_ru IS NOT NULL
        LIMIT 100
    """)
    
    good_questions = 0
    bad_questions = 0
    examples = []
    
    for sql, question in cur.fetchall():
        if is_good_question(question):
            good_questions += 1
            examples.append((sql, question))
        else:
            bad_questions += 1
    
    print(f"\nüìà –ö–∞—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ (–∏–∑ 100):")
    print(f"‚úÖ –•–æ—Ä–æ—à–∏–µ: {good_questions}")
    print(f"‚ùå –ü–ª–æ—Ö–∏–µ: {bad_questions}")
    
    # –ü—Ä–∏–º–µ—Ä—ã –ø–ª–æ—Ö–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    print(f"\n‚ùå –ü—Ä–∏–º–µ—Ä—ã –ø–ª–æ—Ö–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:")
    cur.execute("""
        SELECT sql, question_ru 
        FROM text2sql_captured 
        WHERE question_ru IS NOT NULL 
        AND (question_ru LIKE '–ü–æ–∫–∞–∂–∏ –∏–∑%' OR question_ru LIKE '–ö–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ%')
        LIMIT 5
    """)
    
    for sql, question in cur.fetchall():
        print(f"  SQL: {sql[:100]}...")
        print(f"  –í–æ–ø—Ä–æ—Å: {question}")
        print()
    
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É SQL
    print(f"\nüîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
    cur.execute("""
        SELECT DISTINCT sql, question_ru
        FROM text2sql_captured 
        WHERE question_ru IS NOT NULL
    """)
    
    unique_pairs = {}
    for sql, question in cur.fetchall():
        normalized = normalize_sql(sql)
        if normalized not in unique_pairs:
            unique_pairs[normalized] = (sql, question)
    
    print(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SQL –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(unique_pairs)}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π
    operation_stats = defaultdict(int)
    for normalized_sql in unique_pairs.keys():
        op_type = get_operation_type(normalized_sql)
        operation_stats[op_type] += 1
    
    print(f"\nüìã –ü–æ —Ç–∏–ø–∞–º –æ–ø–µ—Ä–∞—Ü–∏–π:")
    for op_type, count in operation_stats.items():
        print(f"  {op_type}: {count}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
    table_stats = defaultdict(int)
    for sql, _ in unique_pairs.values():
        tables = extract_table_names(sql)
        for table in tables:
            table_stats[table] += 1
    
    print(f"\nüóÇÔ∏è –ü–æ —Ç–∞–±–ª–∏—Ü–∞–º (—Ç–æ–ø-10):")
    for table, count in sorted(table_stats.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"  {table}: {count}")
    
    cur.close()
    conn.close()
    
    return unique_pairs


def create_quality_examples(unique_pairs):
    """–°–æ–∑–¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è few-shot –æ–±—É—á–µ–Ω–∏—è"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    print(f"\nüéØ –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    cur.execute("""
        CREATE TABLE IF NOT EXISTS text2sql_examples (
            id SERIAL PRIMARY KEY,
            normalized_sql TEXT NOT NULL,
            business_question_ru TEXT NOT NULL,
            business_question_en TEXT,
            table_names TEXT[],
            operation_type VARCHAR(10),
            quality_score INTEGER DEFAULT 0,
            source_captured_id INTEGER,
            created_at TIMESTAMP DEFAULT NOW()
        )
    """)
    
    # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    cur.execute("DELETE FROM text2sql_examples")
    
    examples_added = 0
    
    for normalized_sql, (original_sql, question) in unique_pairs.items():
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–∞
        if not is_good_question(question):
            # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å
            table_names = extract_table_names(original_sql)
            operation_type = get_operation_type(original_sql)
            suggested_question = suggest_business_question(original_sql, table_names, operation_type)
            
            if not is_good_question(suggested_question):
                continue  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –ø–ª–æ—Ö–æ–π
            
            question = suggested_question
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        quality_score = calculate_quality_score(question, original_sql)
        
        if quality_score >= 5:  # —Ç–æ–ª—å–∫–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
            table_names = extract_table_names(original_sql)
            operation_type = get_operation_type(original_sql)
            
            cur.execute("""
                INSERT INTO text2sql_examples 
                (normalized_sql, business_question_ru, table_names, operation_type, quality_score)
                VALUES (%s, %s, %s, %s, %s)
            """, (normalized_sql, question, table_names, operation_type, quality_score))
            
            examples_added += 1
    
    conn.commit()
    
    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {examples_added}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
    cur.execute("""
        SELECT 
            COUNT(*) as total,
            AVG(quality_score) as avg_quality,
            COUNT(CASE WHEN quality_score >= 8 THEN 1 END) as excellent,
            COUNT(CASE WHEN quality_score >= 6 THEN 1 END) as good
        FROM text2sql_examples
    """)
    
    total, avg_quality, excellent, good = cur.fetchone()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤:")
    print(f"  –í—Å–µ–≥–æ: {total}")
    print(f"  –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_quality:.1f}")
    print(f"  –û—Ç–ª–∏—á–Ω—ã–µ (8+): {excellent}")
    print(f"  –•–æ—Ä–æ—à–∏–µ (6+): {good}")
    
    cur.close()
    conn.close()


if __name__ == "__main__":
    print("üöÄ –ê–Ω–∞–ª–∏–∑ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è captured SQL –∑–∞–ø—Ä–æ—Å–æ–≤")
    print("=" * 50)
    
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º captured –∑–∞–ø—Ä–æ—Å—ã
        unique_pairs = analyze_captured_queries()
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        create_quality_examples(unique_pairs)
        
        print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
